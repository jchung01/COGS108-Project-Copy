{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Joonsung Park\n",
    "- James Chung\n",
    "- Richard Gross\n",
    "- Madison Hambly\n",
    "- Colin Lintereur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the most popular topics from previous COGS 108 final projects vary per quarter from 2019 to 2021? Also what other trends can we find in past submissions, like changes in word count, and number of graphs used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: Past COGS108 final projects\n",
    "- Link to the dataset: [github.com/COGS108](github.com/COGS108)\n",
    "- Number of observations: ~200 so far\n",
    "\n",
    "We looked through the COGS108 github repositories and downloaded the zip file for each quarter of submissions we wanted to include in out analyis. From there, we loop through each jupyter notebook in the zip file and collect relevant data. We also parse the notebook to find the research of the group. We then generate a csv file for each quarter, and once we have all the csv files we of each quarter, we combine them into the final dataset we want to study. There are more quarters and submissions that are not yet included but we plan to include more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import paralleldots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing libraries, we now search through the zip file of a quarter we want to study. Some data we can find through regex of the filename and some we need to parse the notebook to find. In particular, the research question is difficult to find since the formatting of every submission is not always the same. This may cause the parser to not find any research question or find the wrong cell. However, this is very rare and does not actually ruin our analysis since all we need is a block of text that describes the topic of the project and any block of text near the research question tends to contain relevant information to the topic of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting API key for classifier\n",
    "paralleldots.set_api_key(\"aSWrD1QSsUqdb8JYWJ6jMJMXrTxjFXKhdD4xQZKiUlQ\")\n",
    "\n",
    "# initializing lists\n",
    "research_questions = {}\n",
    "qtr = []\n",
    "year = []\n",
    "group = []\n",
    "special = []\n",
    "word_counts = []\n",
    "index = 0\n",
    "\n",
    "# reading zip file for a certain quarter\n",
    "with zipfile.ZipFile(\"zips/FinalProjects-SP21-main.zip\", \"r\") as f:\n",
    "    for i, name in enumerate(f.namelist()):\n",
    "        # skip files that are not jupyter notebooks\n",
    "        if '.ipynb' not in name:\n",
    "            continue\n",
    "        rf = json.loads(f.read(name))\n",
    "        word_count = 0\n",
    "        rq_found = False\n",
    "        \n",
    "        # loop through every cell\n",
    "        for j, cell in enumerate(rf['cells']):\n",
    "            if cell['cell_type'] == 'markdown':\n",
    "                for c in cell['source']:\n",
    "                    # if cell contains the research question header, update lists and extract the research question from the next cell\n",
    "                    if (rq_found == False) and (re.search(r\"(^#.*research question)\", c.lower()) != None):\n",
    "                        #print(\"RQ FOUND\")\n",
    "                        qtr.append(\"SP\")\n",
    "                        year.append(2021)\n",
    "                        group.append(int(re.search(r\"[$0-9^]{3,}\", name)[0]))\n",
    "                        special.append(False if re.search(r\"_S\\.ipynb\", name) == None else True)\n",
    "                        rq = ' '.join(rf['cells'][j+1]['source'])\n",
    "                        research_questions[str(group[index])+\"_\"+qtr[index]+\"_\"+str(year[index])] = rq          \n",
    "                        rq_found = True\n",
    "                        index += 1\n",
    "                    word_count += len(c.replace('#', '').lstrip().split(' '))\n",
    "        if rq_found:\n",
    "            word_counts.append(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting all the data we need from the submissions, we can use a classifier to find the general topic of the submission. We are currently using an API made by ParallelDots to do this classification for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE:\n",
      " Which factor, among major, college quality, internship experience, and gender, is the most influential on the starting salary of college graduates in the United States?  ::  EDUCATION\n"
     ]
    }
   ],
   "source": [
    "# initialize topics list\n",
    "topic = []\n",
    "\n",
    "# loop through research questions and find the most confident topic class from topic classifier\n",
    "for i, (g, q, y) in enumerate(zip(group, qtr, year)):\n",
    "    response = paralleldots.taxonomy(research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])])\n",
    "    topic.append(response['taxonomy'][0]['tag'])\n",
    "    if i == 0:\n",
    "        print(\"EXAMPLE:\\n\", research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])], \" :: \", topic[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stored the topics of the submissions, we can run a sanity check to make sure that all of our list are the same length and then export the data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 47 47 47 47 47\n"
     ]
    }
   ],
   "source": [
    "# double check that all the lists are the same length\n",
    "print(len(group), len(qtr), len(year), len(topic), len(special), len(word_counts))\n",
    "\n",
    "# generate data frame and output it to a csv file\n",
    "d = {'Group':group, 'Quarter':qtr, 'Year':year, 'Topic':topic, 'Special':special, 'Word_Count':word_counts}\n",
    "df = pd.DataFrame(data = d)\n",
    "output = df.to_csv(path_or_buf=\"./\"+qtr[0] + str(year[0])+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are collecting the data ourselves, there is not much work to be done cleaning the data after collecting all of the csv files for each quarter and merging them together into one large dataset. One column we do need to remove however is a column named 'Unnamed: 0'. This column is an artifact of reading csv files that store index information for each dataset. This column is redundant in our new dataset so we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Special</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>SP</td>\n",
       "      <td>2021</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>False</td>\n",
       "      <td>4399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>SP</td>\n",
       "      <td>2021</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>False</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>SP</td>\n",
       "      <td>2021</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>False</td>\n",
       "      <td>3479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>SP</td>\n",
       "      <td>2021</td>\n",
       "      <td>IMPACT</td>\n",
       "      <td>False</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>SP</td>\n",
       "      <td>2021</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>False</td>\n",
       "      <td>5117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group Quarter  Year      Topic Special  Word_Count\n",
       "0      2      SP  2021  EDUCATION   False        4399\n",
       "1      3      SP  2021  EDUCATION   False        4065\n",
       "2      4      SP  2021   POLITICS   False        3479\n",
       "3      5      SP  2021     IMPACT   False        2691\n",
       "4      6      SP  2021   POLITICS   False        5117"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collecting all dataframes together\n",
    "df_SP21 = pd.read_csv(\"SP2021.csv\")\n",
    "df_WI21 = pd.read_csv(\"WI2021.csv\")\n",
    "df_FA20 = pd.read_csv(\"FA2020.csv\")\n",
    "df_SP20 = pd.read_csv(\"SP2020.csv\")\n",
    "\n",
    "df_total = df_SP21.merge(df_WI21.merge(df_FA20.merge(df_SP20, how='outer'), how='outer'), how='outer')\n",
    "df_total = df_total.drop('Unnamed: 0', axis=1)\n",
    "assert(len(df_total.index) == (len(df_SP21.index)+len(df_WI21.index)+len(df_FA20.index)+len(df_SP20.index)))\n",
    "\n",
    "df_total.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
