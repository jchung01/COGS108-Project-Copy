{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1723e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import paralleldots\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from uclassify import uclassify\n",
    "\n",
    "uclass = uclassify()\n",
    "\n",
    "# copy/paste API key for ParallelDots\n",
    "API_KEY = 'aSWrD1QSsUqdb8JYWJ6jMJMXrTxjFXKhdD4xQZKiUlQ'\n",
    "READ_API_KEY = 'pUllRXrepgLH'\n",
    "\n",
    "# setting API key for classifier\n",
    "paralleldots.set_api_key(API_KEY)\n",
    "uclass.setReadApiKey(READ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cafc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing lists\n",
    "research_questions = {}\n",
    "qtr = []\n",
    "year = []\n",
    "group = []\n",
    "# special projects are marked with '_S' at the end of its name\n",
    "special = []\n",
    "word_counts = []\n",
    "graph_counts = []\n",
    "table_counts = []\n",
    "index = 0\n",
    "\n",
    "# reading zip file for a certain quarter\n",
    "with zipfile.ZipFile(\"zips/FinalProjects-SP21-main.zip\", \"r\") as f:\n",
    "    for i, name in enumerate(f.namelist()):\n",
    "        # skip files that are not jupyter notebooks\n",
    "        if '.ipynb' not in name:\n",
    "            continue\n",
    "        rf = json.loads(f.read(name))\n",
    "        word_count = 0\n",
    "        graph_count = 0\n",
    "        table_count = 0\n",
    "        rq_found = False\n",
    "        \n",
    "        # loop through every cell\n",
    "        for j, cell in enumerate(rf['cells']):\n",
    "            if cell['cell_type'] == 'code':\n",
    "                if ('outputs' in cell) and (cell['outputs'] != []):# and ('data' in cell['outputs'][0]):# and ('image/png' in cell['outputs'][0]['data'])\n",
    "                    for k,_ in enumerate(cell['outputs']):\n",
    "                        if 'data' in cell['outputs'][k]:\n",
    "                            if 'image/png' in cell['outputs'][k]['data']:\n",
    "                                graph_count += 1\n",
    "                            if 'text/html' in cell['outputs'][k]['data']:\n",
    "                                table_count += 1\n",
    "            elif cell['cell_type'] == 'markdown':\n",
    "                for c in cell['source']:\n",
    "                    # if cell contains the research question header, update lists and extract the research question from the next cell\n",
    "                    if (rq_found == False) and (re.search(r\"(^#.*research question)\", c.lower()) != None):\n",
    "                        #print(\\\"RQ FOUND\\\")\n",
    "                        \n",
    "                        # extract quarter info from repo name\n",
    "                        date = re.search(r\"-(.*)-\", name).group(1)\n",
    "                        qtr.append(date[:2].upper())\n",
    "                        year.append(int(date[2:]))\n",
    "\n",
    "                        # extract group number\n",
    "                        fname = re.search(r\"/.*\", name).group(0)\n",
    "                        group.append(int(re.search(r\"[$0-9^]{2,3}\", fname)[0]))\n",
    "\n",
    "                        special.append(False if re.search(r\"_S\\.ipynb\", name) == None else True)\n",
    "                        # get the research question from the cell AFTER the cell that contains the header 'Research Question'\n",
    "                        rq = ' '.join(rf['cells'][j+1]['source'])\n",
    "                        research_questions[str(group[index])+\"_\"+qtr[index]+\"_\"+str(year[index])] = rq\n",
    "                        rq_found = True\n",
    "                        index += 1\n",
    "                    word_count += len(c.replace('#', '').lstrip().split(' '))\n",
    "        if rq_found:\n",
    "            word_counts.append(word_count)\n",
    "            graph_counts.append(graph_count)\n",
    "            table_counts.append(table_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e774f05c",
   "metadata": {},
   "outputs": [
    {
     "ename": "uClassifyError",
     "evalue": "\"Authentification with the api key 'xxxxxxxxxgLH' for the classifier 'Sentiment' failed. The classifier doesn't exist.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31muClassifyError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-51e4eb75aa77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     response = paralleldots.taxonomy(research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     topic.append(response['taxonomy'][0]['tag'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresearch_questions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mqtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     print(\"EXAMPLE:\\n\", research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])], \" :: \", topic[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/uclassify/uclassify.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, texts, classifierName, username)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getResponseCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"false\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0muClassifyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseClassifyResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31muClassifyError\u001b[0m: \"Authentification with the api key 'xxxxxxxxxgLH' for the classifier 'Sentiment' failed. The classifier doesn't exist.\""
     ]
    }
   ],
   "source": [
    "# initialize topics list\n",
    "topic = []\n",
    "\n",
    "# loop through research questions and find the most confident topic class from topic classifier\n",
    "for i, (g, q, y) in enumerate(zip(group, qtr, year)):\n",
    "#     print(i, g, q, y, research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])])\n",
    "#     response = paralleldots.taxonomy(research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])])\n",
    "#     topic.append(response['taxonomy'][0]['tag'])\n",
    "    d = uclass.classify(research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])],\"Sentiment\")\n",
    "    print(d)\n",
    "#     print(\"EXAMPLE:\\n\", research_questions[str(group[i])+\"_\"+qtr[i]+\"_\"+str(year[i])], \" :: \", topic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "068fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "uclass.classify?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
